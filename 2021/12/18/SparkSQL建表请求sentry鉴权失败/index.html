<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="源码版本：Apache Spark 2.4.7 导读：使用 Spark SQL 客户端建表时 Hive MetaStore 端提示没有建表权限，相同的用户和语句在 Hive 客户端是正常执行的，主要原因是开启了 sentry 鉴权，需要将建立的表 role 角色和 HDFS 路径都当作鉴权对象，而 HDFS 路径实际是没有 role 角色控制，在 Hive 中建表的 schema 信息中是没有">
<meta property="og:type" content="article">
<meta property="og:title" content="SparkSQL建表请求sentry鉴权失败">
<meta property="og:url" content="http://yoursite.com/2021/12/18/SparkSQL%E5%BB%BA%E8%A1%A8%E8%AF%B7%E6%B1%82sentry%E9%89%B4%E6%9D%83%E5%A4%B1%E8%B4%A5/index.html">
<meta property="og:site_name" content="笨小康的博客">
<meta property="og:description" content="源码版本：Apache Spark 2.4.7 导读：使用 Spark SQL 客户端建表时 Hive MetaStore 端提示没有建表权限，相同的用户和语句在 Hive 客户端是正常执行的，主要原因是开启了 sentry 鉴权，需要将建立的表 role 角色和 HDFS 路径都当作鉴权对象，而 HDFS 路径实际是没有 role 角色控制，在 Hive 中建表的 schema 信息中是没有">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-12-18T11:23:24.000Z">
<meta property="article:modified_time" content="2021-12-19T11:50:19.757Z">
<meta property="article:author" content="笨小康">
<meta property="article:tag" content="Spark">
<meta property="article:tag" content="Spark源码">
<meta property="article:tag" content="bugfix">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/2021/12/18/SparkSQL%E5%BB%BA%E8%A1%A8%E8%AF%B7%E6%B1%82sentry%E9%89%B4%E6%9D%83%E5%A4%B1%E8%B4%A5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>SparkSQL建表请求sentry鉴权失败 | 笨小康的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">笨小康的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">星辰大海, 如期而至</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签云</a>

  </li>
        <li class="menu-item menu-item-flomo">

    <a href="/categories/flomo/" rel="section"><i class="fa fa-lightbulb fa-fw"></i>随想录</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于我</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜文章
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/12/18/SparkSQL%E5%BB%BA%E8%A1%A8%E8%AF%B7%E6%B1%82sentry%E9%89%B4%E6%9D%83%E5%A4%B1%E8%B4%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="笨小康">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="笨小康的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          SparkSQL建表请求sentry鉴权失败
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-12-18 19:23:24" itemprop="dateCreated datePublished" datetime="2021-12-18T19:23:24+08:00">2021-12-18</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote>
<p>源码版本：Apache Spark 2.4.7</p>
<p>导读：使用 Spark SQL 客户端建表时 Hive MetaStore 端提示没有建表权限，相同的用户和语句在 Hive 客户端是正常执行的，主要原因是开启了 sentry 鉴权，需要将建立的表 role 角色和 HDFS 路径都当作鉴权对象，而 HDFS 路径实际是没有 role 角色控制，在 Hive 中建表的 schema 信息中是没有 location 信息所以 sentry 鉴权会通过，Spark SQL 需要进行和 Hive 类似的处理兼容 SQL 端建表。</p>
</blockquote>
<h1 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h1><p>使用 spark2.4.7-sql 建表发现的异常，用户已经申请 test_db 库权限，并且在 Hive 中建表逻辑是正常的，在 spark-sql 中提示用户没有建表权限。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 常规 spark-sql 建表</span></span><br><span class="line">spark-sql (default)&gt; create external test_db.table tmp_1(id int);</span><br><span class="line"> </span><br><span class="line">Error in query: org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:User 11085244 does not have privileges for CREATETABLE);</span><br></pre></td></tr></table></figure>

<h1 id="2-原因分析"><a href="#2-原因分析" class="headerlink" title="2. 原因分析"></a>2. 原因分析</h1><h2 id="2-1-调试分析"><a href="#2-1-调试分析" class="headerlink" title="2.1 调试分析"></a>2.1 调试分析</h2><p>spark-sql 本身并不提供安全认证机制，当前集群的安全认证主要包括 sentry 和 Ranger 两大块，根据 spark-sql 建表抛出的异常 Error 信息，追溯到异常是从 sentry 代码中抛出的，由于 sentry 中抛异常的位置包含大量 DEBUG 信息，于是开启 sentry 组件的 DEBUG 日志，再次使用 spark-sql 建表，发现 sentry 端抛出如下信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">2021-09-15 11:30:09,964 DEBUG org.apache.hadoop.security.UserGroupInformation: [pool-5-thread-3]: PrivilegedAction as:kwang (auth:SIMPLE) from:org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)</span><br><span class="line">2021-09-15 11:30:09,965 INFO  org.apache.hadoop.hive.ql.log.PerfLogger: [pool-5-thread-3]: &lt;PERFLOG method=create_table_with_environment_context from=org.apache.hadoop.hive.metastore.RetryingHMSHandler&gt;</span><br><span class="line">2021-09-15 11:30:09,965 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore: [pool-5-thread-3]: 3: source:10.101.3.17 create_table: Table(tableName:tmp_1, dbName:test_db, owner:kwang, createTime:1631676574, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null)], location:hdfs://nameservice/hive/warehouse/test_db.db/tmp_1, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:&#123;serialization.format=1&#125;), bucketCols:[], sortCols:[], parameters:&#123;&#125;, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:&#123;&#125;)), partitionKeys:[], parameters:&#123;spark.sql.sources.schema.numParts=1, spark.sql.sources.schema.part.0=&#123;&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[&#123;&quot;name&quot;:&quot;id&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;]&#125;, spark.sql.create.version=2.4.7&#125;, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:&#123;&#125;, groupPrivileges:null, rolePrivileges:null))</span><br><span class="line">2021-09-15 11:30:09,965 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit: [pool-5-thread-3]: ugi=kwang     ip=10.101.3.17  cmd=source:10.101.3.17 create_table: Table(tableName:tmp_1, dbName:test_db, owner:kwang, createTime:1631676574, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:null)], location:hdfs://nameservice/hive/warehouse/test_db.db/tmp_1, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:&#123;serialization.format=1&#125;), bucketCols:[], sortCols:[], parameters:&#123;&#125;, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:&#123;&#125;)), partitionKeys:[], parameters:&#123;spark.sql.sources.schema.numParts=1, spark.sql.sources.schema.part.0=&#123;&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[&#123;&quot;name&quot;:&quot;id&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:&#123;&#125;&#125;]&#125;, spark.sql.create.version=2.4.7&#125;, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:&#123;&#125;, groupPrivileges:null, rolePrivileges:null))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2021-09-15 11:30:09,965 DEBUG org.apache.sentry.binding.hive.authz.HiveAuthzBinding: [pool-5-thread-3]: Going to authorize statement CREATETABLE for subject kwang</span><br><span class="line"></span><br><span class="line">2021-09-15 11:30:09,965 DEBUG org.apache.sentry.binding.hive.authz.HiveAuthzBinding: [pool-5-thread-3]: requiredInputPrivileges = &#123;URI=[ALL]&#125;</span><br><span class="line">2021-09-15 11:30:09,965 DEBUG org.apache.sentry.binding.hive.authz.HiveAuthzBinding: [pool-5-thread-3]: </span><br><span class="line">inputHierarchyList = [</span><br><span class="line">	[Server [name=server1]],</span><br><span class="line">	[Server [name=server1], Database [name=test_db]],</span><br><span class="line">	[Server [name=server1]],</span><br><span class="line">	[Server [name=server1], URI [name=hdfs://nameservice/hive/warehouse/test_db.db/tmp_1]]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">2021-09-15 11:30:09,965 DEBUG org.apache.sentry.binding.hive.authz.HiveAuthzBinding: [pool-5-thread-3]: requiredOuputPrivileges = &#123;Db=[ALL]&#125;</span><br><span class="line">2021-09-15 11:30:09,965 DEBUG org.apache.sentry.binding.hive.authz.HiveAuthzBinding: [pool-5-thread-3]: </span><br><span class="line">outputHierarchyList = [</span><br><span class="line">	[Server [name=server1]],</span><br><span class="line">	[Server [name=server1], Database [name=test_db]]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">2021-09-15 11:30:09,965 DEBUG org.apache.sentry.provider.common.ResourceAuthorizationProvider: [pool-5-thread-3]: Authorization Request for Subject [name=kwang] [Server [name=server1], URI [name=hdfs://nameservice/hive/warehouse/test_db.db/tmp_1]] and [ALL]</span><br><span class="line"></span><br><span class="line">2021-09-18 11:49:03,081 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler: [pool-5-thread-195]: MetaException(message:User kwang does not have privileges for CREATETABLE)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.firePreEvent(HiveMetaStore.java:2136)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table_core(HiveMetaStore.java:1459)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table_with_environment_context(HiveMetaStore.java:1557)</span><br><span class="line">        at sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:497)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:140)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:99)</span><br><span class="line">        at com.sun.proxy.$Proxy11.create_table_with_environment_context(Unknown Source)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_with_environment_context.getResult(ThriftHiveMetastore.java:9974)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_with_environment_context.getResult(ThriftHiveMetastore.java:9958)</span><br><span class="line">        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:110)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:106)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:118)</span><br><span class="line">        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:745)</span><br></pre></td></tr></table></figure>

<p>可以看到 sentry 端在对鉴权对象 <code>URI [name=hdfs://nameservice/hive/warehouse/test_db.db/tmp_1]</code> 路径鉴权时没有权限。而通过 Hive 建表进行鉴权时并没有对 URI 路径进行鉴权，Hive 端传递过来的 location 为 null。这也解释得通为什么 spark-sql 建表权限不通过，因为在 sentry 鉴权过程中用户有对应的 DB role 权限，而 URI role 在 sentry 中并不存在，鉴权也就无法通过。</p>
<h2 id="2-2-鉴权逻辑源码分析"><a href="#2-2-鉴权逻辑源码分析" class="headerlink" title="2.2 鉴权逻辑源码分析"></a>2.2 鉴权逻辑源码分析</h2><p>通过对 sentry 日志的分析，定位到 sentry 鉴权的代码逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 位置：org/apache/sentry/binding/hive/authz/HiveAuthzBinding.java</span></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Validate the privilege for the given operation for the given subject</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">authorize</span><span class="params">(HiveOperation hiveOp, HiveAuthzPrivileges stmtAuthPrivileges,</span></span></span><br><span class="line"><span class="params"><span class="function">      Subject subject, List&lt;List&lt;DBModelAuthorizable&gt;&gt; inputHierarchyList,</span></span></span><br><span class="line"><span class="params"><span class="function">      List&lt;List&lt;DBModelAuthorizable&gt;&gt; outputHierarchyList)</span></span></span><br><span class="line"><span class="function">          <span class="keyword">throws</span> AuthorizationException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!open) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">&quot;Binding has been closed&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">boolean</span> isDebug = LOG.isDebugEnabled();</span><br><span class="line">    <span class="keyword">if</span>(isDebug) &#123;</span><br><span class="line">      LOG.debug(<span class="string">&quot;Going to authorize statement &quot;</span> + hiveOp.name() +</span><br><span class="line">          <span class="string">&quot; for subject &quot;</span> + subject.getName());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* for each read and write entity captured by the compiler -</span></span><br><span class="line"><span class="comment">     *    check if that object type is part of the input/output privilege list</span></span><br><span class="line"><span class="comment">     *    If it is, then validate the access.</span></span><br><span class="line"><span class="comment">     * Note the hive compiler gathers information on additional entities like partitions,</span></span><br><span class="line"><span class="comment">     * etc which are not of our interest at this point. Hence its very</span></span><br><span class="line"><span class="comment">     * much possible that the we won&#x27;t be validating all the entities in the given list</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check read entities</span></span><br><span class="line">    Map&lt;AuthorizableType, EnumSet&lt;DBModelAction&gt;&gt; requiredInputPrivileges =</span><br><span class="line">        stmtAuthPrivileges.getInputPrivileges();</span><br><span class="line">    <span class="keyword">if</span>(isDebug) &#123;</span><br><span class="line">      LOG.debug(<span class="string">&quot;requiredInputPrivileges = &quot;</span> + requiredInputPrivileges);</span><br><span class="line">      LOG.debug(<span class="string">&quot;inputHierarchyList = &quot;</span> + inputHierarchyList);</span><br><span class="line">    &#125;</span><br><span class="line">    Map&lt;AuthorizableType, EnumSet&lt;DBModelAction&gt;&gt; requiredOutputPrivileges =</span><br><span class="line">        stmtAuthPrivileges.getOutputPrivileges();</span><br><span class="line">    <span class="keyword">if</span>(isDebug) &#123;</span><br><span class="line">      LOG.debug(<span class="string">&quot;requiredOuputPrivileges = &quot;</span> + requiredOutputPrivileges);</span><br><span class="line">      LOG.debug(<span class="string">&quot;outputHierarchyList = &quot;</span> + outputHierarchyList);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">boolean</span> found = <span class="keyword">false</span>;</span><br><span class="line">    <span class="comment">// 对 input 对象鉴权</span></span><br><span class="line">    <span class="keyword">for</span>(AuthorizableType key: requiredInputPrivileges.keySet()) &#123;</span><br><span class="line">      <span class="keyword">for</span> (List&lt;DBModelAuthorizable&gt; inputHierarchy : inputHierarchyList) &#123;</span><br><span class="line">        <span class="keyword">if</span> (getAuthzType(inputHierarchy).equals(key)) &#123;</span><br><span class="line">          found = <span class="keyword">true</span>;</span><br><span class="line">          <span class="comment">// 真正鉴权逻辑</span></span><br><span class="line">          <span class="keyword">if</span> (!authProvider.hasAccess(subject, inputHierarchy, requiredInputPrivileges.get(key), activeRoleSet)) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> AuthorizationException(<span class="string">&quot;User &quot;</span> + subject.getName() +</span><br><span class="line">                <span class="string">&quot; does not have privileges for &quot;</span> + hiveOp.name());</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span>(!found &amp;&amp; !(key.equals(AuthorizableType.URI)) &amp;&amp;  !(hiveOp.equals(HiveOperation.QUERY))</span><br><span class="line">          &amp;&amp; !(hiveOp.equals(HiveOperation.CREATETABLE_AS_SELECT))) &#123;</span><br><span class="line">        <span class="comment">//URI privileges are optional for some privileges: anyPrivilege, tableDDLAndOptionalUriPrivilege</span></span><br><span class="line">        <span class="comment">//Query can mean select/insert/analyze where all of them have different required privileges.</span></span><br><span class="line">        <span class="comment">//CreateAsSelect can has table/columns privileges with select.</span></span><br><span class="line">        <span class="comment">//For these alone we skip if there is no equivalent input privilege</span></span><br><span class="line">        <span class="comment">//<span class="doctag">TODO:</span> Even this case should be handled to make sure we do not skip the privilege check if we did not build</span></span><br><span class="line">        <span class="comment">//the input privileges correctly</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> AuthorizationException(<span class="string">&quot;Required privilege( &quot;</span> + key.name() + <span class="string">&quot;) not available in input privileges&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      found = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">	</span><br><span class="line">    <span class="comment">// 对 output 对象鉴权</span></span><br><span class="line">    <span class="keyword">for</span>(AuthorizableType key: requiredOutputPrivileges.keySet()) &#123;</span><br><span class="line">      <span class="keyword">for</span> (List&lt;DBModelAuthorizable&gt; outputHierarchy : outputHierarchyList) &#123;</span><br><span class="line">        <span class="keyword">if</span> (getAuthzType(outputHierarchy).equals(key)) &#123;</span><br><span class="line">          found = <span class="keyword">true</span>;</span><br><span class="line">          <span class="keyword">if</span> (!authProvider.hasAccess(subject, outputHierarchy, requiredOutputPrivileges.get(key), activeRoleSet)) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> AuthorizationException(<span class="string">&quot;User &quot;</span> + subject.getName() +</span><br><span class="line">                <span class="string">&quot; does not have privileges for &quot;</span> + hiveOp.name());</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span>(!found &amp;&amp; !(key.equals(AuthorizableType.URI)) &amp;&amp;  !(hiveOp.equals(HiveOperation.QUERY))) &#123;</span><br><span class="line">        <span class="comment">//URI privileges are optional for some privileges: tableInsertPrivilege</span></span><br><span class="line">        <span class="comment">//Query can mean select/insert/analyze where all of them have different required privileges.</span></span><br><span class="line">        <span class="comment">//For these alone we skip if there is no equivalent output privilege</span></span><br><span class="line">        <span class="comment">//<span class="doctag">TODO:</span> Even this case should be handled to make sure we do not skip the privilege check if we did not build</span></span><br><span class="line">        <span class="comment">//the output privileges correctly</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> AuthorizationException(<span class="string">&quot;Required privilege( &quot;</span> + key.name() + <span class="string">&quot;) not available in output privileges&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      found = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>该方法的传入参数包括：</p>
<ul>
<li><p>hiveOp：当前 sql 的操作类型。</p>
</li>
<li><p>stmtAuthPrivileges：本次操作所需的权限集合。</p>
</li>
<li><p>subject：表示当前操作的用户</p>
</li>
<li><p>inputHierarchyList：sql 请求的输入对象。</p>
</li>
<li><p>outputHierarchyList：sql 请求的输出对象。</p>
</li>
</ul>
<p>用户的鉴权分为两步：</p>
<ol>
<li>用户是否拥有对 input 对象列表的该 operation 对应的访问权限。</li>
<li>用户是否拥有对 output 对象列表的该 operation 对应的访问权限。</li>
</ol>
<p>stmtAuthPrivileges 包含了 input 对象权限 map 和 output 对象权限 map，map 的 key 值为一个 AuthorizableType 枚举对象，取值为 Server/Db/Table/Column/View/URI 中的一种，对于每一个 AuthorizableType，至少有一个 inputList 或 outputList 与其 AuthorizableType 相同，此时通过 Provider 的 hasAccess 方法判断该用户是否对该对象列表拥有相应的权限。</p>
<p>真正校验权限的逻辑在 ResourceAuthorizationProvider 的 doHasAccess 方法中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 位置：org/apache/sentry/provider/common/ResourceAuthorizationProvider.java</span></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">doHasAccess</span><span class="params">(Subject subject,</span></span></span><br><span class="line"><span class="params"><span class="function">      List&lt;? extends Authorizable&gt; authorizables, Set&lt;? extends Action&gt; actions,</span></span></span><br><span class="line"><span class="params"><span class="function">      ActiveRoleSet roleSet)</span> </span>&#123;</span><br><span class="line">    Set&lt;String&gt; groups =  getGroups(subject);</span><br><span class="line">    Set&lt;String&gt; hierarchy = <span class="keyword">new</span> HashSet&lt;String&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Authorizable authorizable : authorizables) &#123;</span><br><span class="line">      hierarchy.add(KV_JOINER.join(authorizable.getTypeName(), authorizable.getName()));</span><br><span class="line">    &#125;</span><br><span class="line">    List&lt;String&gt; requestPrivileges = buildPermissions(authorizables, actions);</span><br><span class="line">    Iterable&lt;Privilege&gt; privileges = getPrivileges(groups, roleSet, authorizables.toArray(<span class="keyword">new</span> Authorizable[<span class="number">0</span>]));</span><br><span class="line">    lastFailedPrivileges.get().clear();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (String requestPrivilege : requestPrivileges) &#123;</span><br><span class="line">      Privilege priv = privilegeFactory.createPrivilege(requestPrivilege);</span><br><span class="line">      <span class="keyword">for</span> (Privilege permission : privileges) &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * Does the permission granted in the policy file imply the requested action?</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">boolean</span> result = permission.implies(priv);</span><br><span class="line">        <span class="keyword">if</span>(LOGGER.isDebugEnabled()) &#123;</span><br><span class="line">          LOGGER.debug(<span class="string">&quot;ProviderPrivilege &#123;&#125;, RequestPrivilege &#123;&#125;, RoleSet, &#123;&#125;, Result &#123;&#125;&quot;</span>,</span><br><span class="line">              <span class="keyword">new</span> Object[]&#123; permission, requestPrivilege, roleSet, result&#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (result) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    lastFailedPrivileges.get().addAll(requestPrivileges);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>sentry 根据用户的组、角色从数据库中读取其拥有的权限，并与需要的权限进行对比，只有当 inputHierarchyList 中的所有权限都符合时，才能通过认证。</p>
<p>通过对 spark-sql 执行时 sentry 日志和 hive-cli 执行时 sentry 日志对比发现，spark-sql 执行传入的 inputHierarchyList 中包含了欲创建表的 location 信息，而该 location URI 在 sentry 中并没有对应的 role 角色，因此对该表的权限认证不能通过。</p>
<h1 id="3-解决方案"><a href="#3-解决方案" class="headerlink" title="3. 解决方案"></a>3. 解决方案</h1><p>通过分析 spark-sql 的源码，spark 创建表的逻辑在 HiveClientImpl 的 createTable 方法中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 位置：org/apache/spark/sql/hive/client/HiveClientImpl.scala</span></span><br><span class="line">  <span class="function">override def <span class="title">createTable</span><span class="params">(table: CatalogTable, ignoreIfExists: Boolean)</span>: Unit </span>= withHiveState &#123;</span><br><span class="line">    verifyColumnDataType(table.dataSchema)</span><br><span class="line">    client.createTable(toHiveTable(table, Some(userName)), ignoreIfExists)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>spark 在这里对 Table 类型进行了转换，将 CatalogTable 转化成 HiveTable，而 CatalogTable 中包含了 location 信息，参照 Hive 建表的方式这里的 location 是多余的。因此，对这块逻辑进行了修改，spark-sql 在执行 createTable 时，去掉 Table 属性的 location 信息，这里只针对内部表进行修改，外部表的创建一般都会指定 location 信息，这里还是保留不变。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 位置：org/apache/spark/sql/hive/client/HiveClientImpl.scala</span></span><br><span class="line">  <span class="function">override def <span class="title">createTable</span><span class="params">(table: CatalogTable, ignoreIfExists: Boolean)</span>: Unit </span>= withHiveState &#123;</span><br><span class="line">    verifyColumnDataType(table.dataSchema)</span><br><span class="line">    val hiveTable = toHiveTable(table, Some(userName))</span><br><span class="line">    <span class="keyword">if</span> (hiveTable.getTableType.equals(HiveTableType.MANAGED_TABLE)</span><br><span class="line">      &amp;&amp; sparkConf.getBoolean(<span class="string">&quot;spark.sql.enable.sentry&quot;</span>, defaultValue = <span class="keyword">true</span>)) &#123;</span><br><span class="line">      hiveTable.getTTable.getSd.setLocation(<span class="keyword">null</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    client.createTable(hiveTable, ignoreIfExists)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li><p><a target="_blank" rel="noopener" href="https://www.huaweicloud.com/articles/12456466.html">sparksql集成sentry遇到的问题</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/shenh062326/document/blob/master/Sentry%E9%89%B4%E6%9D%83%E5%8E%9F%E7%90%86/Sentry%E9%89%B4%E6%9D%83%E5%8E%9F%E7%90%86.md">Sentry鉴权原理</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhanyuanlin/article/details/95898018">Spark对HiveMetastore客户端的多版本管理、兼容性探究以及栅栏实现</a></p>
</li>
</ul>

    </div>

    
    
    

    <div>
      
      <div>
	 
		<div style="text-align:center;color:#bfbfbf;font-size:16px;"> 
			<span>-------- 本文结束 </span> <i class="fa fa-paw"></i> <span> 感谢阅读 --------</span>
		</div> 
	
</div>
      
    </div>
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    请我喝杯咖啡~
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="笨小康 微信打赏">
        <p>微信打赏</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="笨小康 支付宝打赏">
        <p>支付宝打赏</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Spark/" rel="tag"><i class="fa fa-tag"></i> Spark</a>
              <a href="/tags/Spark%E6%BA%90%E7%A0%81/" rel="tag"><i class="fa fa-tag"></i> Spark源码</a>
              <a href="/tags/bugfix/" rel="tag"><i class="fa fa-tag"></i> bugfix</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/12/18/Spark-HistoryServer%E6%97%A5%E5%BF%97%E8%A7%A3%E6%9E%90%E5%BC%82%E5%B8%B8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" rel="prev" title="Spark HistoryServer日志解析异常源码分析">
      <i class="fa fa-chevron-left"></i> Spark HistoryServer日志解析异常源码分析
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/12/19/Java%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%92%E5%BA%8F%E5%99%A8/" rel="next" title="Java如何设计自定义排序器">
      Java如何设计自定义排序器 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  




          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E8%83%8C%E6%99%AF"><span class="nav-text">1. 背景</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90"><span class="nav-text">2. 原因分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-%E8%B0%83%E8%AF%95%E5%88%86%E6%9E%90"><span class="nav-text">2.1 调试分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-%E9%89%B4%E6%9D%83%E9%80%BB%E8%BE%91%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90"><span class="nav-text">2.2 鉴权逻辑源码分析</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-text">3. 解决方案</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-text">参考资料</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">笨小康</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">笨小康</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
